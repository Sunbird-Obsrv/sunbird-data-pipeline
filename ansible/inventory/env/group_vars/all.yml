###################### DP ############################
# Not used
metrics_search_params_bucket: "dev-data-store"
log4j_appender_kafka_topic: "{{env}}.telemetry.backend"

# Every where the value is telemetry-data-store
# Shall we change the value to telemetry-data-store in dev also?
# What's the implication
# Is it azure blob or s3 bucket??
channel_data_exhaust_bucket: dev-data-store


#azure_account_name: "{{dp_azure_account_name}}"
secrets_path: '{{inventory_dir}}/secrets.yml'
artifacts_container: "{{dp_vault_artifacts_container}}"
#azure_storage_secret: "{{sunbird_private_storage_account_key}}"

report_azure_account_name: "{{sunbird_private_storage_account_name}}"
report_azure_storage_secret: "{{sunbird_private_storage_account_key}}"
#azure_storage_secret: "{{dp_vault_azure_account_key}}"
#monasca_log_level: ERROR
resourcemanager: "{{ groups['yarn-master'][0] }}"
yarn_slaves: "{{ groups['yarn-slave']}}"
monitor_yarn_url: "http://{{ resourcemanager }}:8088/ws/v1/cluster/apps?states=RUNNING"

# Artifact upload and download vars
#artifact_azure_account_name: "{{dp_azure_account_name}}"
#artifact_azure_account_key: "{{dp_vault_azure_account_key}}"

# Artifact upload and download vars
#artifact_azure_account_name: "{{dp_azure_account_name}}"
#artifact_azure_account_key: "{{dp_vault_azure_account_key}}"

redis_host: "{{ groups['redis'][0] }}"
metadata_redis_host: "{{ groups['redis'][0] }}"
metadata2_redis_host: "{{ groups['redis'][0] }}"
searchServiceAuthorizationToken: "{{ dp_search_service_authorization_token }}"


# Learning Service organization and location search endpoints
channelSearchServiceEndpoint: "{{ proto}}://{{domain_name}}/api/org/v1/search"
locationSearchServiceEndpoint: "{{ proto}}://{{domain_name}}/api/data/v1/location/search"

__yarn_host__: "{{ groups['yarn-master'][0] }}"
search_service_endpoint: "{{proto}}://{{domain_name}}/api/search/v2/search"
yarn_es_hosts: "{{ groups['telemetry-search-cluster'] | join(',') }}"
env_name: "{{env}}"
kafka_brokers: "{{groups['processing-cluster-kafka']|join(':9092,')}}:9092"
zookeepers: "{{groups['zookeeper']|join(':2181,')}}:2181"
# Ingestion cluster
ingestion_kafka_brokers: "{{groups['processing-cluster-kafka']|join(':9092,')}}:9092"
secor_ingestion_kafka_brokers: "{{groups['processing-cluster-kafka']|join(',')}}"
ingestion_zookeepers: "{{groups['zookeeper']|join(':2181,')}}:2181"

telemetry_schema_directory: /etc/{{env}}/telemetry
telemetry_schema_path: /etc/{{env}}/telemetry/schemas
schema_repo_url: https://github.com/project-sunbird/sunbird-data-pipeline.git
# Create learningall group with LP ips
cassandra_host:  "{{ groups['cassandra'][0] }}"
core_cassandra_host: "{{ groups['core-cassandra'][0] }}"
report_cassandra_host: "{{ groups['report-cassandra'][0] }}"
content_to_vec_url: http://{{ groups['analytics-api'][0] }}:9000/content-to-vec

kibana_base_path : "/pipeline-dashboard"

################ LPA ###########################

analytics_user: analytics
analytics_group: analytics
#azure_storage_account: "{{dp_azure_account_name}}"
#azure_storage_key: "{{dp_vault_azure_account_key}}"


analytics_user_home: /home/{{ analytics_user }}
sbin_path: "{{ analytics_user_home }}/sbin"


# Secor vars
secor:
  properties: ['secor.azure', 'secor.common', 'secor', 'secor.partition', 'log4j']
  artifact_dir: /mount/secor
  artifact_ver: "0.29"
  azure:
    account_name: "{{sunbird_private_storage_account_name}}"
    account_key: "{{sunbird_private_storage_account_key}}"
    container_name: "{{channel_data_exhaust_bucket}}"
  paths: ['/mount/secor', '/mount/secor/reports', '/mount/secor/logs', '/home/analytics/sbin', '/mount/data/analytics']
  channel: "{{secor_alerts_slack_channel}}"

# postgres
# list of databases to be created
# Can move this dictionary to postgres role; but incase we want to generalize roles!!
postgresql_databases:
  - name: analytics
    owner: analytics
    
postgresql_users:
  - name: analytics
    password: "{{dp_vault_pgdb_password}}"

postgres:
  db_url: "{{ groups['postgres'][0] }}"
  db_username: analytics
  db_name: analytics
  db_password: "{{dp_vault_pgdb_password}}"
  db_table_name: "{{env}}_consumer_channel_mapping"
  db_port: 5432
  db_admin_user: analytics
  db_admin_password: "{{dp_vault_pgdb_admin_password}}"

postgres_address_space: 0.0.0.0/0 # Postgres trust address space

lp_composite_search: "http://{{ groups['composite-search-cluster'][0] }}:9200" # Composite Cluster ip of LP
lp_composite_search_host: "{{ groups['composite-search-cluster'][0] }}"
lp_search: "http://{{ groups['search'][0] }}:9000"
lp_url: http://{{ groups['learning'][0] }}:8080/learning-service
service:
  search:
    url: http://{{private_ingressgateway_ip}}/search
    path: /v3/search

cassandra_hierarchy_store_prefix: "{{env}}_"
data_exhaust_token: "{{dp_vault_data_exhaust_token}}"
default_channel: "{{default_org_hash_id}}"

#### backup storage secret
#backup_azure_storage_account_name: "{{dp_azure_account_name}}"
#backup_azure_storage_access_key: "{{dp_vault_azure_account_key}}"

## es backup
es_snapshot_host: "{{ groups['telemetry-search-cluster'][0] }}"
snapshot_base_path: telemetrysearch


# sunbird learner service
sunbird_es_host: "{{groups['core-es']| join(',')}}"

### Druid related vars
overlord_host: "{{ groups['raw-overlord'][0] }}"

### Datapipeline Custom monitoring related vars ###
influxdb: "{{ groups['influxdb'][0] }}"
CONTAINER_NAME_SAMZA: samza-logs
script_path: /usr/local/hadoop

#### samza jobs deployment related vars ####
samza_tar_files_localpath: roles/samza-jobs/defaults

job_names:
  DeDuplication_1:
      job_file_name: 'de-duplication'
  DeNormalization_1:
      job_file_name: 'de-normalization'
  DruidEventsValidator_1:
      job_file_name: 'druid-events-validator'
  EventsRouter_1:
      job_file_name: 'events-router'
  TelemetryExtractor_1:
      job_file_name: 'telemetry-extractor'
  TelemetryLocationUpdater_1:
      job_file_name: 'telemetry-location-updater'
  TelemetryRouter_1:
      job_file_name: 'telemetry-router'
  TelemetryRedacter_1:
      job_file_name: 'telemetry-redacter'
  TelemetryValidator_1:
      job_file_name: 'telemetry-validator'
  DeviceProfileUpdater_1:
      job_file_name: 'device-profile-updater'
  AssessmentAggregator_1:
      job_file_name: 'assessment-aggregator'
  DerivedDeDuplication_1:
      job_file_name: 'derived-de-duplication'
  UserCacheUpdater_1:
      job_file_name: 'user-cache-updater'
  ContentCacheUpdater_1:
      job_file_name: 'content-cache-updater'
  ShareEventsFlattener_1:
      job_file_name: 'share-events-flattener'    

druid_ingestion_specs:
  telemetry-events:
      ingestion_file_name: 'telemetry_index_kafka'
  summary-events:
      ingestion_file_name: 'summary_index_kafka'
  telemtry-feedback-events:
      ingestion_file_name: 'telemetry_feedback_index_kafka'
  pipeline-metrics:
      ingestion_file_name: 'pipeline_metrics_index_kafka'

#Druid Proxy APi service
sunbird_druid_broker_host: "http://{{ groups['raw-broker'][0] }}"
sunbird_learner_service_url: "{{swarm_manager_lb_ip}}:9000"

location_search_url: "{{ domain_name }}/api/data/"
location_search_token: "Bearer {{ dp_search_service_authorization_token }}"

druid_report_url_endpoint : "{{ proto}}://{{domain_name}}/api/data/v1/report/jobs"
druid_report_url : "{{ proto}}://{{domain_name}}/api/data/v1/"
druid_report_token : "Bearer {{ sunbird_api_auth_token }}"

#redis multiprocess config
content_port: 6379
device_port: 6380
user_port: 6381
dialcode_port: 6382

### kafka and zookeeper ip vars and being used in kafka topiccreation role. 
ingestion_zookeeper_ip: "{{ groups['ingestion-cluster-zookeeper'][0] }}"
processing_zookeeper_ip: "{{ groups['processing-cluster-zookeepers'][0] }}"
