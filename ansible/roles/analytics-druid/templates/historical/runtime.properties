druid.service={{ druid_historical_service }}
druid.host={{ ansible_host }}
druid.port={{ druid_historical_port }}


# HTTP server threads
druid.server.http.numThreads={{ druid_configs[cluster].druid_historical_server_http_numThread }}

# Processing threads and buffers
druid.processing.buffer.sizeBytes={{ druid_configs[cluster].druid_historical_processing_bufferBytes }}
druid.processing.numThreads={{ druid_configs[cluster].druid_historical_processing_threads }}
druid.processing.numMergeBuffers={{ druid_configs[cluster].druid_historical_processing_num_merge_buffers }}

# Segment storage
#druid.segmentCache.locations=[{"path": "{{ druid_historical_segmentcache_path }}", "maxSize": {{ druid_configs[cluster].druid_historical_segmentcache_size }}}]
druid.segmentCache.locations=[{% for number in range(5) %}{"path": "{{ druid_configs[cluster].druid_historical_segmentcache_path }}{{number }}", "maxSize": {{ druid_configs[cluster].druid_historical_segmentcache_size }}}{% if not loop.last %}, {% endif %}
{% endfor %}]

druid.segmentCache.numLoadingThreads={{ druid_configs[cluster].druid_historical_segmentcache_numloadingthreads }}

{% if druid_historical_monitoring_monitors is defined %}
# Monitors
druid.monitoring.monitors=[{{ druid_historical_monitoring_monitors }}]
{% endif %}

{% if druid_configs[cluster].druid_query_ondiskstorage_enabled %}
druid.query.groupBy.maxMergingDictionarySize={{ druid_configs[cluster].druid_historical_maxMergingDictionarySize }}
druid.query.groupBy.maxOnDiskStorage={{ druid_configs[cluster].druid_historical_maxOnDiskStorage }}
{% endif %}


# Caching
druid.historical.cache.useCache={{ druid_configs[cluster].druid_historical_enable_cache }} 
druid.historical.cache.populateCache=true
druid.historical.cache.unCacheable=["select","scan"]
druid.cache.type=caffeine
druid.cache.sizeInBytes={{ druid_historical_cache_size }}
druid.cache.expireAfter={{ druid_historical_cache_expiry }}
