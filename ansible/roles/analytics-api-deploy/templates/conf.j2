application.env="{{ env }}"
spark.cassandra.connection.host={{groups['dp-cassandra'][0]}}
service.search.url="{{lp_search}}"
service.search.path="/v2/search"
service.search.requestbody="""{"request":{"filters":{"objectType":["Content"],"contentType":["Story","Worksheet","Collection","Game"],"status":["Live"]},"limit":1000}}"""
service.search.limit="10"

metrics.creation.es.url="{{lp_composite_search}}"
metrics.creation.es.indexes="compositesearch"


recommendation.enable=true
recommendation.limit="10"
recommendation.surprise_find.enable=true
recommendation.surprise_find.index="15"
recommendation.surprise_find.serendipity_factor="20"

dataproduct.scripts_path="/mount/data/analytics/scripts"

# Metrics API
# metrics.period.format.day="MMM dd EEE"
# metrics.period.format.month="MMM YYYY"
# metrics.period.format.year="YYYY"


# Data Exhaust API
data_exhaust.list.limit="100"
data_exhaust.retry.limit="3"
data_exhaust.dataset.list=["eks-consumption-raw", "eks-consumption-summary", "eks-consumption-metrics","eks-creation-raw", "eks-creation-summary", "eks-creation-metrics"]
data_exhaust.dataset.default="eks-consumption-raw"
data_exhaust.output_format="json"

# Log4j Kafka appender config
log4j.appender.kafka.enable="true"
log4j.appender.kafka.broker_host="{{groups['processing-cluster-kafka'][0]}}:9092"
log4j.appender.kafka.topic="{{env}}.telemetry.log"

cassandra.service.embedded.enable=false
cassandra.keyspace_prefix="{{ cassandra.keyspace_prefix }}"

#AKKA Configuration
akka {
  actor {
    deployment {

        /metricsApiActor {
            router = smallest-mailbox-pool
            nr-of-instances = 10
        }
        /jobApiActor {
            router = smallest-mailbox-pool
            nr-of-instances = 10
        }
        /recommendAPIActor {
            router = smallest-mailbox-pool
            nr-of-instances = 10
        }
        /healthCheckAPIActor {
            router = smallest-mailbox-pool
            nr-of-instances = 10
        }
        /tagServiceAPIActor {
          router = smallest-mailbox-pool
            nr-of-instances = 10
        }
        /deviceRegisterServiceAPIActor {
          router = smallest-mailbox-pool
            nr-of-instances = 20
        }
    }

    default-dispatcher {
      executor = "fork-join-executor"
      fork-join-executor {
      # The parallelism factor is used to determine thread pool size using the
      # following formula: ceil(available processors * factor). Resulting size
      # is then bounded by the parallelism-min and parallelism-max values.
      parallelism-factor = 3.0

      # Min number of threads to cap factor-based parallelism number to
      parallelism-min = 8

       # Max number of threads to cap factor-based parallelism number to
       parallelism-max = 64
     }
     # Throughput for default Dispatcher, set to 1 for as fair as possible
       throughput = 1
    }
  }
}

#Netty Configuration
play.server {

  # The server provider class name
  provider = "play.core.server.NettyServerProvider"

  netty {

    # The number of event loop threads. 0 means let Netty decide, which by default will select 2 times the number of
    # available processors.
    eventLoopThreads = 30

    # Whether the Netty wire should be logged
    log.wire = true

    # The transport to use, either jdk or native.
    # Native socket transport has higher performance and produces less garbage but are only available on linux
    transport = "native"
  }
}

play.modules.enabled+="MetricsModule"


default.consumption.app.id="no_value"
default.channel.id="{{default_channel_id}}"
default.creation.app.id="no_value"

postgres.db="{{postgres.db_name}}"
postgres.url="jdbc:postgresql://{{ postgres.db_url }}:5432/"
postgres.user="{{ postgres.db_username }}"
postgres.pass="{{ postgres.db_password }}"
postgres.table_name="{{ postgres.db_table_name }}"
postgres.table.geo_location_city.name="{{ geo_location_city }}"
postgres.table.geo_location_city_ipv4.name="{{ geo_location_city_ipv4 }}"

default.channel="{{ default_channel }}"

elasticsearch.service.endpoint="http://{{groups['composite-search-cluster'][0]}}:9200"
elasticsearch.index.compositesearch.name="compositesearch"
elasticsearch.index.dialcodemetrics.name="dialcodemetrics"
metrics.dialcodemetrics.request.limit=1000

#channel specifix telemetry exhaust

dataexhaust.authorization_check=true

channel.data_exhaust.bucket="{{channel_data_exhaust_bucket}}"
channel.data_exhaust.basePrefix="channel/"
channel.data_exhaust.expiryMins=30
storage-service.request-signature-version="AWS4-HMAC-SHA256"
s3service.region="ap-south-1"

cloud_storage_type="azure"
