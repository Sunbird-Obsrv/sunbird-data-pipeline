 - name: Create Directory for Jobs
   file: path={{ item }} owner=hduser group=hadoop recurse=yes state=directory
   with_items:
     - "{{ samza_jobs_dir }}"
     - "{{ samza_jobs_dir }}/extract"

 - name: Get the application id to kill the app
   shell: "{{ yarn_path }}/yarn application --list | grep -i {{ item }} | awk '{print $1}'"
   with_items: "{{ job_names_to_kill.split(',')|list }}"
   register: appid

 - name: Kill the mentioned applications
   shell: "{{ yarn_path }}/yarn application -kill {{ item.stdout }}"
   with_items:
     - "{{ appid['results'] }}"
   when: item.stdout | length > 0

 - name: find the existing file names to remove
   find:
     paths: "{{ samza_jobs_dir }}"
     patterns: "{{ job_names['%s'|format(item)].job_file_name }}*"
     recurse: yes
   with_items: "{{ job_names_to_kill.split(',') }}"
   register: existing_files

 - name: remove the files under "{{ samza_jobs_dir }}" directory
   command: rm -rf "{{ item.path | basename }}"
   with_items: "{{ existing_files | json_query('results[].files[]') }}"
   args:
      chdir: "{{ samza_jobs_dir }}"

 - name: remove the files under "{{ samza_jobs_dir }}/extract" directory
   command: rm -rf "{{ item.path | basename }}"
   with_items: "{{ existing_files | json_query('results[].files[]') }}"
   args:
      chdir: "{{ samza_jobs_dir }}/extract"

 - name: copy new jobs tar ball
   copy: src={{ item }} dest={{ samza_jobs_dir }}/ force=no owner=hduser group=hadoop
   with_fileglob:
     - ../defaults/jobs/*
   register: new_jobs

 - name: Create directory to extract new jobs
   file: path="{{ samza_jobs_dir }}/extract/{{ item }}" owner=hduser group=hadoop recurse=yes state=directory
   with_items:
     - "{{ new_jobs | json_query('results[].invocation.module_args.original_basename') }}"

 - name: extract new jobs
   unarchive:
         src: "{{ samza_jobs_dir }}/{{ item }}"
         dest: "{{ samza_jobs_dir }}/extract/{{ item }}"
         remote_src: yes
   with_items:
     - "{{ new_jobs | json_query('results[].invocation.module_args.original_basename') }}"

 - name: Get all new jobs config
   shell: "ls -d -1 {{ samza_jobs_dir }}/extract/{{ item }}/config/*.properties"
   register: config_files
   with_items:
     - "{{ new_jobs | json_query('results[].invocation.module_args.original_basename') }}"

 - name: update environment specific details in new job configs
   replace: dest="{{ item[1].stdout }}" regexp="{{ item[0].key }}" replace="{{ item[0].value }}"
   with_nested:
     - [{key: "__yarn_host__", value: "{{ __yarn_host__ }}"}, {key: "__yarn_port__", value: "{{ __yarn_port__ }}"}, {key: "__env__", value: "{{ env }}" }, {key: "__env_name__", value: "{{ env_name }}" }, {key: "__zookeepers__", value: "{{ zookeepers }}"}, {key: "__kafka_brokers__", value: "{{ kafka_brokers }}"}, {key: "__delayInMilliSeconds__", value: "{{ delayInMilliSeconds }}" }, {key: "__retryTimeInMilliSeconds__", value: "{{ retryTimeInMilliSeconds }}" }, {key: "__bypass_reverse_search__", value: "{{ bypass_reverse_search }}" }, {key: "__retryBackoffBaseInSeconds__", value: "{{ retry_backoff_base_in_seconds }}" }, {key: "__retryLimit__", value: "{{ retry_limit }}" }, {key: "__retryLimitEnable__", value: "{{ retry_limit_enable }}" },  {key: "__google_api_key__", value: "{{ google_api_key }}" }, {key: "__searchServiceEndpoint__", value: "{{ search_service_endpoint }}" }, {key: "__environment_id__", value: "{{ environment_id }}"}, {key: "__google_vision_tagging__", value: "{{ google_vision_tagging }}"}, {key: "__cassandra_host__", value: "{{ cassandra_host }}"},{key: "__cassandra_port__", value: "{{ cassandra_port }}"}, {key: "__content_to_vec_url__", value: "{{ content_to_vec_url }}"},{key: "__max_iteration_count_for_samza_job__", value: "{{ max_iteration_count_for_samza_job }}"},{key: "__device_profile_updater_yarn_container_count__", value: "{{ device_profile_updater_yarn_container_count }}"},{key: "__telemetry_extractor_yarn_container_count__", value: "{{ telemetry_extractor_yarn_container_count }}"},{key: "__telemetry_validator_yarn_container_count__", value: "{{ telemetry_validator_yarn_container_count }}"},{key: "__telemetry_de_duplication_yarn_container_count__", value: "{{ telemetry_de_duplication_yarn_container_count }}"},{key: "__telemetry_router_yarn_container_count__", value: "{{ telemetry_router_yarn_container_count }}"},{key: "__telemetry_reverse_search_yarn_container_count__", value: "{{ telemetry_reverse_search_yarn_container_count }}"},{key: "__telemetry_object_de_normalization_yarn_container_count__", value: "{{ telemetry_object_de_normalization_yarn_container_count }}"}, {key: "__events_router_yarn_container_count__", value: "{{ events_router_yarn_container_count }}"}, {key: "__ingestion_zookeepers__", value: "{{ zookeepers }}"},{key: "__tr_secondary_route_events__", value: "{{ tr_secondary_route_events }}"},{key: "__telemetry_schema_path__", value: "{{ telemetry_schema_path }}"},{key: "__default_channel__", value: "{{ default_channel }}"},{key: "__telemetry_location_updater_yarn_container_count__", value: "{{ telemetry_location_updater_yarn_container_count }}"},{key: "__channelSearchServiceEndpoint__", value: "{{ channelSearchServiceEndpoint }}"},{key: "__locationSearchServiceEndpoint__", value: "{{ locationSearchServiceEndpoint }}"},{key: "__searchServiceAuthorizationToken__", value: "{{ searchServiceAuthorizationToken }}"},{key: "__redis_host__", value: "{{ redis_host }}"}, {key: "__redis_port__", value: "{{ redis_port }}"},{key: "__location_db_redis_key_expiry_seconds__", value: "{{ location_db_redis_key_expiry_seconds }}"}, {key: "__cache_unresolved_location_key_expiry_seconds__", value: "{{ cache_unresolved_location_key_expiry_seconds }}"}, {key: "__middleware_cassandra_host__", value: "{{ core_cassandra_host }}"},{key: "__middleware_cassandra_port__", value: "{{ cassandra_port }}"},{key: "__middleware_cassandra_keyspace__", value: "{{ middleware_cassandra_keyspace }}"}, {key: "__middleware_cassandra_user_table__", value: "{{ middleware_cassandra_user_table }}"}, {key: "__middleware_cassandra_location_table__", value: "{{ middleware_cassandra_location_table }}"}, {key: "__telemetry_extractor_consumer_fetch_max_bytes__", value: "{{ telemetry_extractor_consumer_fetch_max_bytes }}"}, {key: "__telemetry_extractor_container_memory_mb__", value: "{{ telemetry_extractor_container_memory_mb }}"}, {key: "__telemetry_extractor_messages_fetch_threshold__", value: "{{ telemetry_extractor_messages_fetch_threshold }}"}, {key: "__denormalization_yarn_container_count__", value: "{{ denormalization_yarn_container_count }}"}, {key: "__druidprocessor_yarn_container_count__", value: "{{ druidprocessor_yarn_container_count }}"}, {key: "__content_metadata_fields__", value: "{{ content_metadata_fields }}"}, {key: "__user_metadata_fields__", value: "{{ user_metadata_fields }}"}, {key: "__dialcode_metadata_fields__", value: "{{ dialcode_metadata_fields }}"}, {key: "__druid_events_validator_yarn_container_count__", value: "{{ druid_events_validator_yarn_container_count }}"}, {key: "__redis_updater_yarn_container_count__", value: "{{ redis_updater_yarn_container_count }}"}, {key: "__samza_checkpoint_replication_factor__", value: "{{ samza_checkpoint_replication_factor }}"}, {key: "__consumer_fetch_max_bytes__", value: "{{ consumer_fetch_max_bytes }}"}, {key: "__producer_max_request_size_bytes__", value: "{{ producer_max_request_size_bytes }}"}, {key: "__dedup_include_producer_ids__", value: "{{ dedup_include_env_producer_ids }}"}, {key: "__user_sigin_type_default__", value: "{{ user_signin_type_default }}"}, {key: "__user_login_type_default__", value: "{{ user_login_type_default }}"}]
     - "{{ config_files | json_query('results[]') }}"

 - name: Start the jobs
   shell: "{{ samza_jobs_dir }}/extract/{{ item.0 }}/bin/run-job.sh --config-factory=org.apache.samza.config.factories.PropertiesConfigFactory --config-path={{ item.1.stdout }}"
   with_together:
     - "{{ new_jobs | json_query('results[].invocation.module_args.original_basename') }}"
     - "{{ config_files | json_query('results[]') }}"
