analytics_user: analytics
analytics_group: analytics
telemetry_converter_ver: 0.0.8

bucket: "dev-data-store"
brokerlist: "{{groups['processing-cluster-kafka'][0]}}:9092"
zookeeper: "{{groups['processing-cluster-kafka'][0]}}:2181"
dp_username: dp-monitor
analytics_job_queue_topic: "{{ env }}.analytics.job_queue"
datasetRawBucket: ekstep-data-sets-{{ env }}
dataExhaustBucket: ekstep-public-{{ env }}
dataExhaustPrefix: data-exhaust/
consumptionRawPrefix: datasets/D001/4208ab995984d222b59299e5103d350a842d8d41/
topic: "{{ env }}.telemetry.derived"
learning_topic: "{{ env }}.learning.graph.events"
analytics_metrics_topic: "{{ env }}.analytics_metrics"
sink_topic: "{{ env }}.telemetry.sink"
metrics_topic: "{{ env }}.telemetry.metrics"
job_manager_tmp_dir: "transient-data"
channel: dev-test
druid_broker_host: "{{groups['broker'][0]}}"
analytics_job_list: '"wfs", "wfus", "workflow-usage-metrics", "portal-metrics", "dialcode-usage-summary", "dialcode-usage-updater", "etb-coverage-summary", "data-exhaust", "pipeline-failed-events-audit", "pipeline-druid-events-audit", "pipeline-audit", "ds", "dpu", "monitor-job-summ"'
analytics_jobs_count: 14

cassandra_keyspace_prefix: '{{ env }}_'
dp_dispatch_bucket_name: ekstep-dev-data-store
data_exhaust_blob_name: sunbird1p7
data_exhaust_s3_url: https://s3-ap-south-1.amazonaws.com

heap_memory: "-Xmx5120m"

business_metrics:
  s3_path: "s3://ekstep-{{ env }}-data-store/business_metrics/"
  env: "{{ env }}"

spark:
  home: "{{ analytics.home }}/spark-2.0.1-bin-hadoop2.7"
  public_dns: 54.255.154.146
  master:
    url: spark://172.31.11.117:7077
    host: 172.31.11.117
  worker:
    instances: 1
    cores: 2
    memory: 4g
  driver:
    memory: 3g
  executor:
    memory: 4g
  driver_memory: 7g
  memory_fraction: 0.3
  storage_fraction: 0.5  
  executor_extraJavaOptions: -Dconfig.file=/mnt/data/analytics/models/{{ env }}.conf -Dlog4j.configurationFile=file:///mnt/data/analytics/models/log4j2.xml
  driver_extraJavaOptions: -Dconfig.file=/mnt/data/analytics/models/{{ env }}.conf -Dlog4j.configurationFile=file:///mnt/data/analytics/models/log4j2.xml
  executor_memory: 2g
  heap_conf_str: '"-XX:+UseG1GC -XX:MaxGCPauseMillis=100 -Xms250m {{ heap_memory }} -XX:+UseStringDeduplication"'

submit_jobs:
  submit-all-jobs:
    hour: 00
    minute: 35

start_jobmanager:
  job-manager:
    hour: 00
    minute: 30
have_weekly_jobs: false

video_stream_job_schedule: 10

run_course_metrics_job:
  course-dashboard-metrics:
    hour: 21
    minute: 30

run_assessment_metrics_job:
  assessment-dashboard-metrics:
    hour: 22
    minute: 30

run_admin_user_reports_job:
  admin-user-reports:
    hour: 4
    minute: 30

update_user_redis_cache:
  populate-user-cache:
    hour: 3
    minute: 00

index_content_model_druid:
  index_content:
    hour: 1
    minute: 00

service:
  search:
    url: http://{{groups['search1'][0]}}:9000
    path: /v3/search

es_search_index: "compositesearch"
analytics:
  home: /mount/data/analytics
  soft_path: /mount/data/analytics
  paths: ['/home/analytics/sbin', '/mount/data/analytics', '/mount/data/analytics/logs', '/mount/data/analytics/logs/services', '/mount/data/analytics/logs/data-products', '/mount/data/analytics/logs/api-service', '/mount/data/analytics/api', '/mount/data/analytics/tmp', '/mount/data/analytics/scripts/monitor-data', '/mount/data/analytics/models' ]
  scripts: ['model-config', 'replay-job', 'replay-updater', 'replay-utils', 'run-job', 'monitor-dp', 'generate-metrics', 'submit-job', 'start-jobmanager']


producer_env: "dev"