analytics_user: analytics
analytics_group: analytics
spark_output_temp_dir: /mount/data/analytics/tmp/

bucket: "dev-data-store"
kafka_broker_host: "{{groups['processing-cluster-kafka'][0]}}:9092"
ingestion_kafka_broker_host: "{{groups['ingestion-cluster-kafka'][0]}}:9092"
brokerlist: "{{groups['processing-cluster-kafka']|join(':9092,')}}:9092"
zookeeper: "{{groups['processing-cluster-zookeepers']|join(':2181,')}}:2181"
dp_username: dp-monitor
analytics_job_queue_topic: "{{ env }}.analytics.job_queue"
topic: "{{ env }}.telemetry.derived"
analytics_metrics_topic: "{{ env }}.analytics_metrics"
sink_topic: "{{ env }}.telemetry.sink"
assess_topic: "{{ env }}.telemetry.assess"
metrics_topic: "{{ env }}.telemetry.metrics"
job_manager_tmp_dir: "transient-data"
channel: dev-test
druid_broker_host: "{{groups['raw-broker'][0]}}"
druid_rollup_broker_host: "{{groups['raw-broker'][0]}}"
hierarchySearchServiceUrl: "{{ proto }}://{{ domain_name }}/action/content"
hierarchySearchServicEndpoint: /v3/hierarchy/

user_table_keyspace: "sunbird"
course_keyspace: "sunbird_courses"
hierarchy_store_keyspace: "{{ env }}_hierarchy_store"
job_request_table: "{{ env }}_job_request"
report_user_table_keyspace: "sunbird_courses"


analytics_job_list: '"wfs", "content-rating-updater", "monitor-job-summ"'
analytics_jobs_count: 3

cassandra_keyspace_prefix: '{{ env }}_'
cassandra_hierarchy_store_keyspace: "{{ env_name}}_hierarchy_store"
spark_version: 2.4.4

heap_memory: "-Xmx5120m"

spark:
  home: "{{ analytics.home }}/spark-{{ spark_version }}-bin-hadoop2.7"
  public_dns: 54.255.154.146
  master:
    url: spark://172.31.11.117:7077
    host: 172.31.11.117
  worker:
    instances: 1
    cores: 2
    memory: 4g
  driver:
    memory: 3g
  executor:
    memory: 4g
  driver_memory: 7g
  memory_fraction: 0.3
  storage_fraction: 0.5  
  executor_memory: 2g
  heap_conf_str: '"-XX:+UseG1GC -XX:MaxGCPauseMillis=100 -Xms250m {{ heap_memory }} -XX:+UseStringDeduplication"'

submit_jobs:
  submit-all-jobs:
    hour: 02
    minute: 35

start_jobmanager:
  job-manager:
    hour: 02
    minute: 30
have_weekly_jobs: false

course_batch_status_updater_job_schedule: 60

run_wfs_job:
  wfs:
    hour: 00
    minute: 30
run_monitor_job:    
  monitor-job-summ:
    hour: 03
    minute: 00

run_admin_user_reports_job:
  admin-user-reports-3AMIST:
    hour: 21
    minute: 30
  admin-user-reports-2PMIST:
    hour: 8
    minute: 30  

run_admin_geo_reports_job:
  admin-geo-reports-4AMIST:
    hour: 22
    minute: 30
  admin-geo-reports-3PMIST:
    hour: 9
    minute: 30     

run_assessment_aggregator_report_job:
  assessment-aggregator-report:
    hour: 18
    minute: 35

update_user_redis_cache:
  populate-user-cache:
    hour: 3
    minute: 00

index_content_model_druid:
  index_content:
    hour: 1
    minute: 00

run_etb_metrics_weekly_job:
  etb-metrics-weekly:
    hour: 23
    minute: 30
    weekday: 1

# These are the dummy times till sept30 for exhaust reports
#To-Do: Update time after 3.2.7 deployment

run_progress_exhaust:
  progress-exhaust:
    hour: 08
    minute: 00

run_response_exhaust:
  response-exhaust:
    hour: 09
    minute: 00

run_userinfo_exhaust:
  userinfo-exhaust:
    hour: 10
    minute: 00

run_collection_summary:
  collection-summary:
    hour: 09
    minute: 30

run_cassandra_migration:
  cassandra-migration:
    hour: 19
    minute: 15


service:
  search:
    url: http://{{private_ingressgateway_ip}}/search
    path: /v3/search

es_search_index: "compositesearch"
analytics:
  home: /mount/data/analytics
  soft_path: /mount/data/analytics
  paths: ['/mount/data/analytics', '/mount/data/analytics/logs', '/mount/data/analytics/logs/services', '/mount/data/analytics/logs/data-products', '/mount/data/analytics/tmp', '/mount/data/analytics/scripts', '/mount/data/analytics/models' ]
  scripts: ['model-config', 'replay-job', 'replay-updater', 'replay-utils', 'run-job', 'submit-job', 'start-jobmanager', 'submit-script']
  dockScripts: ['model-dock-config','run-dock-job']

# artifact versions
analytics_core_artifact_ver: "2.0"
analytics_ed_dataporducts_artifact_ver: "1.0"
scruid_artifact_ver: "2.4.0"

producer_env: "dev.sunbird"
analytics_job_manager_artifact: "job-manager-{{ analytics_core_artifact_ver }}.jar"
analytics_core_artifact: "analytics-framework-{{ analytics_core_artifact_ver }}.jar"
scruid_artifact: "scruid_2.11-{{ scruid_artifact_ver }}.jar"
analytics_batch_module_artifact: "batch-models-{{ analytics_core_artifact_ver }}.jar"
analytics_ed_dataporducts_artifact: "data-products-{{ analytics_ed_dataporducts_artifact_ver }}-distribution.tar.gz"
model_version: "2.0" 

submit_jobs_auth_token: "{{ sunbird_api_auth_token }}"
report_list_jobs_url: "{{ druid_report_url }}"

reports_container: "reports"

# Cluster vars
spark_cluster_user_password: ""
spark_cluster_user_name: ""
admin_name: "{{ spark_cluster_user_name }}"
admin_password: "{{ spark_cluster_user_password }}"
spark_cluster_name: "{{env}}-spark-cluster"

spark_cluster:
  executor_core: 5
  executor_memory: 19G
  num_executors: 5

analytics_cluster:
  home: "/tmp"

analytics_ed_dataporducts_jar_artifact: "data-products-{{ analytics_ed_dataporducts_artifact_ver }}.jar"  

spark_enable_dynamic_allocation: false
# Spark Cassandra config-vars
spark_cassandra_connection_timeout_millis: 30000
spark_cassandra_query_timeout_millis: 180000
spark_cassandra_query_max_rows_fetch_count: 1000
spark_sql_shuffle_partitions: 200

druid_report_postgres_db_name: druid
druid_report_postgres_db_username: druid


#Override this variable in production and point to druid rollup ingestion cluster 
# Example: "http://$rollup_cluster_ip:8090"
druid_rollup_cluster_ingestion_task_url: "http://{{groups['raw-overlord'][0]}}:8081"
