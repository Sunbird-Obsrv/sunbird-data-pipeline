# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.

####Environment

# Job
job.factory.class=org.apache.samza.job.yarn.YarnJobFactory
job.name=__env__.TelemetryExtractor

# YARN
#yarn.package.path=file://${basedir}/target/${project.artifactId}-${pom.version}-distribution.tar.gz
yarn.package.path=http://__yarn_host__:__yarn_port__/__env__/${project.artifactId}-${pom.version}-distribution.tar.gz
job.container.count=__telemetry_extractor_yarn_container_count__
yarn.container.memory.mb=__telemetry_extractor_container_memory_mb__

# Task
task.class=org.ekstep.ep.samza.task.TelemetryExtractorTask
task.inputs=kafka.__env__.telemetry.ingest
task.checkpoint.factory=org.apache.samza.checkpoint.kafka.KafkaCheckpointManagerFactory
task.checkpoint.system=kafka
# Normally, this would be 3, but we have only one broker.
task.checkpoint.replication.factor=__samza_checkpoint_replication_factor__
task.commit.ms=60000
task.window.ms=300000

# Metrics
metrics.reporters=snapshot,jmx
metrics.reporter.snapshot.class=org.apache.samza.metrics.reporter.MetricsSnapshotReporterFactory
metrics.reporter.snapshot.stream=kafka.__env__.metrics
metrics.reporter.jmx.class=org.apache.samza.metrics.reporter.JmxReporterFactory

# Serializers
serializers.registry.json.class=org.apache.samza.serializers.JsonSerdeFactory
serializers.registry.string.class=org.apache.samza.serializers.StringSerdeFactory
serializers.registry.metrics.class=org.apache.samza.serializers.MetricsSnapshotSerdeFactory

# Systems
systems.kafka.samza.factory=org.apache.samza.system.kafka.KafkaSystemFactory
systems.kafka.samza.msg.serde=string
systems.kafka.samza.key.serde=string
systems.kafka.streams.__env__.metrics.samza.msg.serde=metrics
# systems.kafka.consumer.zookeeper.connect=localhost:2181/
systems.kafka.consumer.zookeeper.connect=__zookeepers__
systems.kafka.consumer.auto.offset.reset=smallest
systems.kafka.samza.offset.default=oldest
systems.kafka.producer.bootstrap.servers=__kafka_brokers__
systems.kafka.consumer.fetch.message.max.bytes=__telemetry_extractor_consumer_fetch_max_bytes__
systems.kafka.producer.max.request.size=__telemetry_extractor_consumer_fetch_max_bytes__
systems.kafka.samza.fetch.threshold=__telemetry_extractor_messages_fetch_threshold__


## Job Coordinator
job.coordinator.system=kafka
job.coordinator.replication.factor=__samza_checkpoint_replication_factor__

output.success.topic.name=__env__.telemetry.raw
output.assess.topic.name=__env__.telemetry.assess.redact
output.error.topic.name=__env__.telemetry.extractor.failed
output.metrics.topic.name=__env__.pipeline_metrics
output.prometheus.metrics.topic.name=__env__.prom.monitoring.metrics
pipeline.metrics.list=success-message-count,skipped-message-count,error-message-count,batch-success-count,batch-error-count,duplicate-event-count,assess-route-success-count
default.channel=__default_channel__

# redis
#redis.host=localhost
redis.host=__redis_host__
#redis.port=6379
redis.port=__redis_port__
redis.connection.max=2
redis.connection.idle.max=2
redis.connection.idle.min=1
redis.connection.minEvictableIdleTimeSeconds=120
redis.connection.timeBetweenEvictionRunsSeconds=300
redis.database.duplicationstore.id=1
redis.database.key.expiry.seconds=432000
raw.individual.event.maxsize=996148

####Local
## Job
#job.factory.class=org.apache.samza.job.yarn.YarnJobFactory
#job.name=TelemetryExtractor

## YARN
#yarn.package.path=file://${basedir}/target/${project.artifactId}-${pom.version}-distribution.tar.gz

## Task
#task.inputs=kafka.telemetry.ingest

## Metrics
#metrics.reporter.snapshot.stream=kafka.metrics

##Key-Value store
#stores.telemetry-extractor.changelog=kafka.telemetry-extractor-changelog

## Systems
#systems.kafka.consumer.zookeeper.connect=localhost:2181/
#systems.kafka.producer.bootstrap.servers=localhost:9092

## Job Coordinator
#output.success.topic.name=telemetry.raw
#output.error.topic.name=telemetry.extractor.failed
#output.metrics.topic.name=pipeline_metrics