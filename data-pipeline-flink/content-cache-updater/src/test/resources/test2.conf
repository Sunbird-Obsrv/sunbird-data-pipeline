kafka {
  denorm.input.topic = "k8s.telemetry.unique.flink"
  output.success.topic = "k8s.telemetry.denorm.flink"
  output.failed.topic = "k8s.telemetry.failed.flink"
  output.metrics.topic = "k8s.telemetry.metrics.flink"
  broker-servers = "127.0.0.1:9092"
  zookeeper = "127.0.0.1:2181"
  event.max.size = "996148" # Max is only 1MB
  groupId = "telemetry-extractor-group"
}

task {
  parallelism = 1
  checkpointing.interval = 60000
  device.denorm.parallelism = 1
  user.denorm.parallelism = 1
  content.denorm.parallelism = 1
  loc.denorm.parallelism = 1
  dialcode.denorm.parallelism = 1
  restart-strategy.attempts = 1 # retry once
  restart-strategy.delay = 1000 # in milli-seconds
  metrics.window.size = 5000 # 5 seconds for test cases
  
}

# redis-metadata
redis-meta {
  database {
    contentstore.id = 5
    dialcodestore.id = 6
  }
  content.host = "localhost"
  dialcode.host = "localhost"
  content.port = 6340
  dialcode.port = 6340
}

telemetry.ignore.period.months = 6
summary.filter.events = ["ME_WORKFLOW_SUMMARY","ME_RANDOM_SUMMARY"]
user.signin.type.default = "Default"
user.login.type.default = "Google"