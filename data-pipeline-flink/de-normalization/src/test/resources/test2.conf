include "base-test.conf"

kafka {
  input.telemetry.topic = "flink.telemetry.unique"
  input.summary.topic = "flink.telemetry.derived"
  telemetry.denorm.output.topic = "flink.telemetry.denorm"
  summary.denorm.output.topic = "flink.druid.events.summary"
  summary.unique.events.topic = "flink.telemetry.derived.unique"
  output.failed.topic = "flink.telemetry.failed"
  output.duplicate.topic = "flink.telemetry.duplicate"
  groupId = "flink-telemetry-denorm-group"
}

task {
  window.count = 1
  window.shards = 10
  telemetry.downstream.operators.parallelism = 1
  summary.downstream.operators.parallelism = 1
}

skip.events = ["INTERRUPT"]
permit.eid=["AUDIT"]

redis {
  host = 127.0.0.1
  port = 6340
  database {
    duplicationstore.id = 9
    key.expiry.seconds = 3600
  }
}

redis-meta {
  host = 127.0.0.1
  port = 6340
  database {
    devicestore.id = 2
    userstore.id = 12
    contentstore.id = 5
    dialcodestore.id = 6
  }
  content.host = "localhost"
  device.host = "localhost"
  user.host = "localhost"
  dialcode.host = "localhost"
  content.port = 6340
  device.port = 6340
  user.port = 6340
  dialcode.port = 6340
}

telemetry.ignore.period.months = 6
summary.filter.events = ["ME_WORKFLOW_SUMMARY","ME_RANDOM_SUMMARY"]
user.signin.type.default = "Default"
user.login.type.default = "Google"