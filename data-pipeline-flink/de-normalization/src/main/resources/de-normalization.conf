include "base-config.conf"

kafka {
  input.telemetry.topic = ${job.env}".telemetry.unique"
  input.summary.topic = ${job.env}".telemetry.derived"
  telemetry.denorm.output.topic = ${job.env}".telemetry.denorm"
  summary.denorm.output.topic = ${job.env}".druid.events.summary"
  summary.unique.events.topic = ${job.env}".telemetry.derived.unique"
  output.failed.topic = ${job.env}".telemetry.failed"
  output.duplicate.topic = ${job.env}".telemetry.duplicate"
  groupId = ${job.env}"-telemetry-denorm-group"
}

task {
  window.count = 30
  window.shards = 1400
  consumer.parallelism = 1
  telemetry.downstream.operators.parallelism = 1
  summary.downstream.operators.parallelism = 1
}

skip.events = ["INTERRUPT"]

redis {
  database {
    duplicationstore.id = 9
    key.expiry.seconds = 3600
  }
}

# redis-metadata
redis-meta {
  database {
    devicestore.id = 2
    userstore.id = 12
    contentstore.id = 5
    dialcodestore.id = 6
  }
  content.host = "localhost"
  device.host = "localhost"
  user.host = "localhost"
  dialcode.host = "localhost"
  content.port = 6380
  device.port = 6381
  user.port = 6382
  dialcode.port = 6383
}