kafka {
  map.input.topic = "local.telemetry.map.input"
  map.output.topic = "local.telemetry.map.output"
  event.input.topic = "local.telemetry.event.input"
  event.output.topic = "local.telemetry.event.output"
  string.input.topic = "local.telemetry.string.input"
  string.output.topic = "local.telemetry.string.output"
  producer.broker-servers = "localhost:9093"
  consumer.broker-servers = "localhost:9093"
  groupId = "pipeline-preprocessor-group"
  auto.offset.reset = "earliest"
  producer {
    max-request-size = 102400
    batch.size = 8192
    linger.ms = 1
    compression = "snappy"
  }
}

kafka.output.metrics.topic = "pipeline_metrics"
task {
  checkpointing.compressed = true
  parallelism = 1
  consumer.parallelism = 1
  checkpointing.interval = 60000
  checkpointing.pause.between.seconds = 30000
  metrics.window.size = 100 # 3 min
  restart-strategy.attempts = 1 # retry once
  restart-strategy.delay = 1000 # in milli-seconds
}

redisdb.connection.timeout = 30000

redis {
  host = 127.0.0.1
  port = 6341
  database {
    duplicationstore.id = 12
    key.expiry.seconds = 3600
  }
}

redis-meta {
  host = localhost
  port = 6341
}

postgress {
    host = localhost
    port = 5432
    maxConnection = 2
    user = "postgres"
    password = "postgres"
}
