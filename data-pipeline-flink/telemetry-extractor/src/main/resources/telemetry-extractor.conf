include "base-config.conf"

kafka {
  input.topic = ${job.env}".telemetry.ingest"
  output.success.topic = ${job.env}".telemetry.raw"
  output.duplicate.topic = ${job.env}".telemetry.extractor.duplicate"
  output.failed.topic = ${job.env}".telemetry.failed"
  output.batch.failed.topic = ${job.env}".telemetry.extractor.failed"
  output.assess.raw.topic = ${job.env}".telemetry.assess.raw"
  event.max.size = "1048576" # Max is only 1MB
  groupId = ${job.env}"-telemetry-extractor-group"
  producer {
    max-request-size = 5242880
  }
}

task {
  consumer.parallelism = 1
  dedup.parallelism = 1
  extraction.parallelism = 1
  redactor.parallelism = 1
}

redis {
  database {
    duplicationstore.id = 1
    key.expiry.seconds = 3600
    contentstore.id = 5
  }
}

redact.events.list = ["ASSESS","RESPONSE"]